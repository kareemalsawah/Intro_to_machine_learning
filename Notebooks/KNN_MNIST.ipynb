{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok, now that we have our libraries, let's import our data\n",
    "#### For our first example, we will use a classic dataset \"MNIST\":\n",
    "MNIST is one of the most famous dataset that was used as a benchmark for many machine learning models. Currently it is outdated because it was too easy. By the end of the course, the MNIST dataset will appear too easy as well, but for now it is a good start.\n",
    "#### So what is the MNIST dataset?\n",
    "\n",
    "This dataset is made of 28 x 28 grayscale images (each pixel is somewhere between black and white, no RGB). Each image represents a hand written english digit. The dataset contains 60000 training examples and 10000 testing examples.\n",
    "<br>\n",
    "<br>\n",
    "![MNIST Dataset](mnist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from a previously saved file\n",
    "with open(\"mnist.pkl\",'rb') as f:\n",
    "        mnist = pickle.load(f)\n",
    "        \n",
    "# Divide the dataset into seperate variable for training and testing\n",
    "# Also the images will be called X and the labels will be called y (example: training_X[0] is the digit 5 and the label \"5\" is training_y[0])\n",
    "training_X, training_y, testing_X, testing_y = mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have our data, let's see our first algorithm\n",
    "\n",
    "## KNN (K-nearest neighbors)\n",
    "One of the most famous algorithms that is easy to implement and performs very well. To start, we will discuss the nearest neighbor algorithm (only one neighbor and not many neighbors)\n",
    "\n",
    "### Nearest neighbor\n",
    "The idea is very simple. Let's say we have many points in R2 as the training data each of them has a label as shown in figure 1.1 below.\n",
    "\n",
    "We are given a new point and we are to determine which label to put on that point. See figure 1.2\n",
    "\n",
    "A simple idea is to search for the point \"closest\" to the given point and use that label. That is exactly the nearest neighbor algorithm. Why did we use \"quotations\" on the word \"closest\"? Because we need to define what closest means. It means the point with the least distance to our given point.\n",
    "\n",
    "To do that we need to define a distance measure. We can use many measures. The first one that probably came to your mind was the euclidean distance calculated using the formula $$\\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}$$\n",
    "\n",
    "This is one of the better distance measures to use in nearest neighbor. But there are other distance measures, some are presented below:\n",
    "\n",
    "#### Euclidean distance\n",
    "This is the one with the formula presented above generalized for more than one component\n",
    "$$\\sqrt{(x_2-x_1)^2+(y_2-y_1)^2+(z_2-z_1)^2....}$$\n",
    "\n",
    "#### MSE (mean squared error)\n",
    "If x = [x1,x2,x2] and y = [y1,y2,y3], $$AverageOverAllComponentsOf((x_2-x_1)^2)$$\n",
    "\n",
    "#### RMSE (root mean squared error)\n",
    "This is simply $$\\sqrt{MSE}$$\n",
    "\n",
    "\n",
    "\n",
    "## Ok, now that we are done with nearest neighbor, let's see K nearest neighbors\n",
    "This is just as the previous algorithm except that instead of finding the closest point (only 1 point), we search for the neasrest K points (that why they are multiple neighbors). Then we see what label is present the most in these K points. To see why this could be a good idea let's see this example of a digit that was misclassified using nearest neighbor but using K nearest neighbors caused a correct classification.\n",
    "\n",
    "Ok so K nearest neighbors might be better, but how do we choose K? Unfortunately, there is no good answer to this. The best way is to try our multiple K values and graph them with the error each one has. Then find the minimum of the graph to find the optimal K. However, make sure that the dataset you use to test each K value is different from the training dataset. Also make sure that after you choose K, you test the model using a test dataset the model hasn't seen previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's implement the KNN algorithm\n",
    "# Note that we will prefer using classes to implement algorithm because they can be reused with a wider variety of dataset\n",
    "\n",
    "class KNN():\n",
    "    def __init__(self,K,training_data,training_labels,type_of_distance_measure):\n",
    "        self.K = K\n",
    "        self.data_X = training_data\n",
    "        self.data_y = training_labels\n",
    "        \n",
    "        if type_of_distance_measure==\"MSE\":\n",
    "            self.distance_measure = self.compareMSE\n",
    "        elif type_of_distance_measure==\"RMSE\":\n",
    "            self.distance_measure = self.compareRMSE\n",
    "        elif type_of_distance_measure==\"Euclidean\":\n",
    "            self.distance_measure = self.compareEuclidean\n",
    "        else:\n",
    "            print(\"Error, {} is not defined as a distance measure!\".format(type_of_distance_measure))\n",
    "        \n",
    "    def predict(self,x_input):\n",
    "        \n",
    "        # Calculating the distance between the given input point and all points in the training dataset\n",
    "        distances = []\n",
    "        for image in self.data_X:\n",
    "            distance = self.distance_measure(x_input,image)\n",
    "            distances.append(distance)\n",
    "            \n",
    "        # Find neasrest K points\n",
    "        nearest_K_indices = np.argsort(distances)[:K]\n",
    "        \n",
    "        # Find the labels of those nearest K points and add them to an array\n",
    "        neighbor_labels = []\n",
    "        for i in nearest_K_indices:\n",
    "            neighbor_label = self.data_y[sorted_indices[i]]\n",
    "            neighbor_labels.append(neighbor_label)\n",
    "        \n",
    "        # See which labels is most presented in our K points\n",
    "        values,counts = np.unique(neighbor_labels,return_counts=True)\n",
    "        best_index=np.argmax(counts)\n",
    "        return values[best_index]\n",
    "        \n",
    "    def compareMSE(self,x1,x2):\n",
    "        x2 = np.array(x2)/255\n",
    "        x1 = np.array(x1)/255\n",
    "        diff = x1-x2\n",
    "        squared_diff = diff*diff\n",
    "        MSE = squared_diff.mean()\n",
    "        return MSE\n",
    "    \n",
    "    def compareEuclidean(self,x1,x2):\n",
    "        x2 = np.array(x2)/255\n",
    "        x1 = np.array(x1)/255\n",
    "        diff = x1-x2\n",
    "        squared_diff = diff*diff\n",
    "        SSE = squared_diff.sum()\n",
    "        return np.sqrt(SSE)\n",
    "    \n",
    "    def compareRMSE(self,x1,x2):\n",
    "        x2 = np.array(x2)/255\n",
    "        x1 = np.array(x1)/255\n",
    "        diff = x1-x2\n",
    "        abs_diff = abs(diff)\n",
    "        RMSE = np.mean(abs_diff)\n",
    "        return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function is used to test our model\n",
    "Inputs:\n",
    "model: our model which needs to have a method \"predict\" that takes input and returns label\n",
    "test_X: testing images\n",
    "test_y: testing labels\n",
    "verbose: If true, detailed accuracy, precision, recall, and f1 scores will be printed, otherwise nothing will be printed\n",
    "\n",
    "Returns:\n",
    "overall_accuracy: accuracy of the model over all classes\n",
    "overall_precision: precision of the model over all classes\n",
    "overall_recall: recall of the model over all classes\n",
    "overall_f1: f1 score of the model over all classes\n",
    "'''\n",
    "def test_model(model,test_X,test_y,verbose=True):\n",
    "    true_positives = np.zeros(10)\n",
    "    false_positives = np.zeros(10)\n",
    "    true_negatives = np.zeros(10)\n",
    "    false_negatives = np.zeros(10)\n",
    "    for x,y in tqdm(zip(test_X,test_y)):\n",
    "        prediction = model.predict(x)\n",
    "        if prediction == y:\n",
    "            true_positives[y] += 1\n",
    "            for i in range(10):\n",
    "                if i != y:\n",
    "                    true_negatives[i] += 1\n",
    "        else:\n",
    "            false_positives[prediction] += 1\n",
    "            false_negatives[y] += 1\n",
    "            for i in range(10):\n",
    "                if i != y and i!= prediction:\n",
    "                    true_negatives[i] += 1\n",
    "    overall_accuracy = (true_positives.sum()+true_negatives.sum())/(true_positives.sum()+true_negatives.sum()+false_positives.sum()+false_negatives.sum())\n",
    "    accuracies = (true_positives+true_negatives)/(true_positives+true_negatives+false_positives+false_negatives)\n",
    "    \n",
    "    overall_precision = true_positives.sum()/(true_positives.sum()+false_positives.sum())\n",
    "    precisions = true_positives/(true_positives+false_positives)\n",
    "    \n",
    "    overall_recall = true_positives.sum()/(true_positives.sum()+false_negatives.sum())\n",
    "    recalls = true_positives/(true_positives+false_negatives)\n",
    "    \n",
    "    overall_f1 = 2*(overall_recall*overall_precision)/(overall_recall+overall_precision)\n",
    "    f1s = 2*(recalls*precisions)/(recalls+precisions)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Accuracy Measures:\")\n",
    "        for i in range(10):\n",
    "            print(str(i)+\" : {}%\".format(accuracies[i]*100))\n",
    "        print(\"Overall Accuracy : {}%\".format(overall_accuracy*100))\n",
    "\n",
    "        print(\"Precision Measures:\")\n",
    "        for i in range(10):\n",
    "            print(str(i)+\" : {}%\".format(precisions[i]*100))\n",
    "        print(\"Overall Precision : {}%\".format(overall_precision*100))\n",
    "\n",
    "        print(\"Recall Measures:\")\n",
    "        for i in range(10):\n",
    "            print(str(i)+\" : {}%\".format(recalls[i]*100))\n",
    "        print(\"Overall Recall : {}%\".format(overall_recall*100))\n",
    "\n",
    "        print(\"F1 Measures:\")\n",
    "        for i in range(10):\n",
    "            print(str(i)+\" : {}%\".format(f1s[i]*100))\n",
    "        print(\"Overall F1 : {}%\".format(overall_f1*100))\n",
    "    \n",
    "    return overall_accuracy,overall_precision,overall_recall,overall_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [03:35,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1 has an accuracy=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [03:40,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=2 has an accuracy=0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [03:48,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=3 has an accuracy=0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78it [03:01,  2.26s/it]"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "number_of_tests = 100\n",
    "Ks_to_test = [1,2,3,5,7,9,11,15,20,25,35,50]\n",
    "for k in Ks_to_test:\n",
    "    model = KNN(k,training_X,training_y,\"Euclidean\")\n",
    "    accuracy,precision,recall,f1 = test_model(model,testing_X[:number_of_tests],testing_y[:number_of_tests],verbose=False)\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)\n",
    "    print(\"K={} has an accuracy={}\".format(k,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
